{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\leocb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     C:\\Users\\leocb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\leocb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\leocb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg, webtext, reuters\n",
    "import random\n",
    "from lib.process_text import clean_text, tokenize_document, remove_stopwords, lemmatize_doc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Download the corpora\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('webtext')\n",
    "nltk.download('reuters')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52659\n"
     ]
    }
   ],
   "source": [
    "# gutenberg\n",
    "sentences_gutenberg = []\n",
    "for fid in range(8):\n",
    "    story = gutenberg.fileids()[fid]\n",
    "    sentences_gutenberg.extend(gutenberg.sents(story))\n",
    "    \n",
    "print(len(sentences_gutenberg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Cookie', 'Manager', ':', '\"', 'Don', \"'\", 't', 'allow', 'sites', 'that', 'set', 'removed', 'cookies', 'to', 'set', 'future', 'cookies', '\"', 'should', 'stay', 'checked', 'When', 'in', 'full', 'screen', 'mode', 'Pressing', 'Ctrl', '-', 'N', 'should', 'open', 'a', 'new', 'browser', 'when', 'only', 'download', 'dialog', 'is', 'left', 'open', 'add', 'icons', 'to', 'context', 'menu', 'So', 'called', '\"', 'tab', 'bar', '\"', 'should', 'be', 'made', 'a', 'proper', 'toolbar', 'or', 'given', 'the', 'ability', 'collapse', '/', 'expand', '.'], ['[', 'XUL', ']', 'Implement', 'Cocoa', '-', 'style', 'toolbar', 'customization', '.'], ...]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25733"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_webtext = webtext.sents()\n",
    "print(sentences_webtext)\n",
    "len(sentences_webtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.'], ['They', 'told', 'Reuter', 'correspondents', 'in', 'Asian', 'capitals', 'a', 'U', '.', 'S', '.', 'Move', 'against', 'Japan', 'might', 'boost', 'protectionist', 'sentiment', 'in', 'the', 'U', '.', 'S', '.', 'And', 'lead', 'to', 'curbs', 'on', 'American', 'imports', 'of', 'their', 'products', '.'], ...]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54716"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_reuters = reuters.sents()\n",
    "print(sentences_reuters)\n",
    "len(sentences_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9713\n"
     ]
    }
   ],
   "source": [
    "all_sentences = list(sentences_gutenberg + sentences_webtext + sentences_reuters)\n",
    "random.seed(123)\n",
    "sentences_random = random.sample(all_sentences, 9713)\n",
    "print(len(sentences_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['as dinner was not to be ready in less than two hours from their arrival elinor determined to employ the interval in writing to her mother and sat down for that purpose ', 'do you want money or a bagel ', ' and he ran unto eli and said here am i for thou calledst me ', 'conchemco inc lt ckc sets quarterly qtly div cts vs cts prior pay april six record march ', 'that doesn t make him a social worker ', ' after him repaired nehemiah the son of azbuk the ruler of the half part of bethzur unto the place over against the sepulchres of david and to the pool that was made and unto the house of the mighty ', 'she always watched them as long as she could delighted to fancy she understood what they might be talking of as they walked along in happy independence or equally delighted to see the admiral s hearty shake of the hand when he encountered an old friend and observe their eagerness of conversation when occasionally forming into a little knot of the navy mrs croft looking as intelligent and keen as any of the officers around her ', 'this was owing to higher agricultural production and the kenyan shilling s relative strength against other major currencies the report said ', 'he said britain west germany the netherlands and denmark continue to oppose the tax after the commission proposed making it temporary and promising compensation to any third countries whose exports suffered ', ' lt unicoa to merge into its united insurance unit unicoa corp said it agreed to a merger with its wholly owned subsidiary united insurance co of america ']\n"
     ]
    }
   ],
   "source": [
    "# clean text\n",
    "sentences = [clean_text(\" \".join(l)) for l in sentences_random]\n",
    "print(sentences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['as', 'dinner', 'was', 'not', 'to', 'be', 'ready', 'in', 'less', 'than', 'two', 'hours', 'from', 'their', 'arrival', 'elinor', 'determined', 'to', 'employ', 'the', 'interval', 'in', 'writing', 'to', 'her', 'mother', 'and', 'sat', 'down', 'for', 'that', 'purpose']\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "token_docs = []\n",
    "for doc in sentences:\n",
    "    token_docs.append(tokenize_document(doc))\n",
    "print(token_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\leocb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 9713/9713 [00:00<00:00, 38066.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dinner', 'ready', 'less', 'two', 'hours', 'arrival', 'elinor', 'determined', 'employ', 'interval', 'writing', 'mother', 'sat', 'purpose']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# remove stop-words\n",
    "sentences = remove_stopwords(token_docs)\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dinner', 'ready', 'le', 'two', 'hour', 'arrival', 'elinor', 'determined', 'employ', 'interval', 'writing', 'mother', 'sat', 'purpose']\n"
     ]
    }
   ],
   "source": [
    "# lemmatize\n",
    "not_amazon_reviews = []\n",
    "\n",
    "for doc in sentences:\n",
    "    not_amazon_reviews.append(lemmatize_doc(doc))\n",
    "\n",
    "print(not_amazon_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9713 entries, 0 to 9712\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Ratings        9713 non-null   int64 \n",
      " 1   Comment        9713 non-null   object\n",
      " 2   Review_tokens  9713 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 227.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# load amazon reviews\n",
    "df_amazon_reviews = pd.read_parquet('data/amazon_reviews.parquet')\n",
    "df_amazon_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "len(not_amazon_reviews)\n",
    "\n",
    "y = [0]*len(not_amazon_reviews) + [1]*len(df_amazon_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9713"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_amazon_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews = df_amazon_reviews[\"Review_tokens\"]\n",
    "not_amazon_reviews = pd.Series(not_amazon_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(amazon_reviews) + len(not_amazon_reviews) == len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19426 entries, 0 to 9712\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  19426 non-null  object\n",
      " 1   Label     19426 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 455.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_reviews = pd.DataFrame(columns=[\"Sentence\",\"Label\"])\n",
    "df_reviews[\"Sentence\"] = pd.concat([not_amazon_reviews,amazon_reviews])\n",
    "df_reviews[\"Label\"] = y\n",
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Sentence  Label\n",
      "0     [dinner, ready, le, two, hour, arrival, elinor...      0\n",
      "1                                  [want, money, bagel]      0\n",
      "2                [ran, unto, eli, said, thou, calledst]      0\n",
      "3     [conchemco, inc, lt, ckc, set, quarterly, qtly...      0\n",
      "4                                [make, social, worker]      0\n",
      "...                                                 ...    ...\n",
      "9708                            [absolutely, brilliant]      1\n",
      "9709  [superb, phone, th, iphone, feel, se, thinnest...      1\n",
      "9710                                             [nice]      1\n",
      "9711                            [loving, good, product]      1\n",
      "9712                            [niceelegant, electric]      1\n",
      "\n",
      "[19426 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Sentence  Label\n",
      "0                                                 [nice]      1\n",
      "1      [man, cell, baby, butter, thang, cause, coming...      0\n",
      "2      [performance, phone, good, problem, batteryit,...      1\n",
      "3                              [nice, one, online, fast]      1\n",
      "4              [old, man, hiccup, old, lady, kill, dead]      0\n",
      "...                                                  ...    ...\n",
      "19421                            [make, better, andriod]      1\n",
      "19422  [cloud, tarried, long, upon, tabernacle, many,...      0\n",
      "19423                                      [good, phone]      1\n",
      "19424                                             [good]      1\n",
      "19425  [excellent, phone, latest, feature, iphone, se...      1\n",
      "\n",
      "[19426 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# shuffle the DataFrame's rows\n",
    "df_reviews_shuffle = df_reviews.sample(frac=1, random_state=123)\n",
    "\n",
    "# Reset the index of the shuffled DataFrame\n",
    "df_reviews_shuffle = df_reviews_shuffle.reset_index(drop=True)\n",
    "\n",
    "print(df_reviews_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leocb\\OneDrive\\Documentos\\Projects\\ReviewsAnalysis\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "# load the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# split with stratification\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(list(df_reviews_shuffle['Sentence']), list(df_reviews_shuffle['Label']), stratify=list(df_reviews_shuffle['Label']), test_size=0.2)\n",
    "\n",
    "# untokenize\n",
    "train_texts_joined = [' '.join(tokens) for tokens in train_texts]\n",
    "test_texts_joined = [' '.join(tokens) for tokens in test_texts]\n",
    "\n",
    "# convert texts to BERT input format with padding and truncation\n",
    "train_encodings = tokenizer(train_texts_joined, truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_texts_joined, truncation=True, padding=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_encodings))\n",
    "print(type(test_encodings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "print(train_encodings.keys())\n",
    "print(test_encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n",
      "238\n"
     ]
    }
   ],
   "source": [
    "print(len(train_encodings['input_ids'][0]))\n",
    "print(len(test_encodings['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 18059, 7367, 1050, 2094, 8991, 5294, 2224, 13151, 3674]\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_encodings['input_ids'][0][:10])\n",
    "print(test_encodings['attention_mask'][0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert encodings to PyTorch dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ReviewsDataset(train_encodings, train_labels)\n",
    "test_dataset = ReviewsDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 69%|██████▊   | 500/729 [4:49:55<2:09:46, 34.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1537, 'learning_rate': 5e-05, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 729/729 [7:05:09<00:00, 34.99s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 25509.3695, 'train_samples_per_second': 1.828, 'train_steps_per_second': 0.029, 'train_loss': 0.11257640160977922, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=729, training_loss=0.11257640160977922, metrics={'train_runtime': 25509.3695, 'train_samples_per_second': 1.828, 'train_steps_per_second': 0.029, 'train_loss': 0.11257640160977922, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize distilbert model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# train model\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=64,  # batch size per device during training\n",
    "    per_device_eval_batch_size=128,  # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset            # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/review_classifier_tokenizer\\\\tokenizer_config.json',\n",
       " 'data/review_classifier_tokenizer\\\\special_tokens_map.json',\n",
       " 'data/review_classifier_tokenizer\\\\vocab.txt',\n",
       " 'data/review_classifier_tokenizer\\\\added_tokens.json',\n",
       " 'data/review_classifier_tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "trainer.save_model(\"data/review_classifier\")\n",
    "\n",
    "# save tokenizer\n",
    "tokenizer.save_pretrained(\"data/review_classifier_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [06:35<00:00, 12.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.04180752858519554,\n",
       " 'eval_runtime': 409.474,\n",
       " 'eval_samples_per_second': 9.49,\n",
       " 'eval_steps_per_second': 0.076,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [06:46<00:00, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.999091847981418\n",
      "Accuracy: 0.9866186309830159\n",
      "Precision: 0.9851205746536685\n",
      "Recall: 0.9881626351003603\n",
      "F1-score: 0.986639260020555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# the predictions are in a tuple with the first item being the prediction scores\n",
    "prediction_scores = predictions[0]\n",
    "\n",
    "# the scores are in the format of (num_samples, num_classes), \n",
    "# and we need to get the score for the positive class\n",
    "positive_class_scores = prediction_scores[:, 1]\n",
    "\n",
    "# calculate AUC-ROC\n",
    "auc_roc = roc_auc_score(test_dataset.labels, positive_class_scores)\n",
    "\n",
    "print(f\"AUC-ROC: {auc_roc}\")\n",
    "\n",
    "# Get the predicted classes\n",
    "preds = predictions[0].argmax(-1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_dataset.labels, preds)\n",
    "precision = precision_score(test_dataset.labels, preds)\n",
    "recall = recall_score(test_dataset.labels, preds)\n",
    "f1 = f1_score(test_dataset.labels, preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'book', 'is', 'pretty', 'good', ',', 'I', 'recommend', 'it']\n",
      "['This', 'book', 'pretty', 'good', ',', 'I', 'recommend']\n",
      "['This', 'book', 'pretty', 'good', ',', 'I', 'recommend']\n",
      "{'input_ids': tensor([[  101,  2023,  2338,  3492,  2204,  1010,  1045, 16755,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# save tokenizer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text = \"This iPhone is great, I love this product!\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"data/review_classifier_tokenizer\")\n",
    "\n",
    "tokenized_text = tokenize_document(text)\n",
    "print(tokenized_text)\n",
    "\n",
    "def remove_stopwords_sentence(tokens):\n",
    "    for word in tokens:\n",
    "        if word in stopwords.words('english'):\n",
    "            tokens.remove(word)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "text_nostop = remove_stopwords_sentence(tokenized_text)\n",
    "print(text_nostop)\n",
    "\n",
    "text_lemmatized = lemmatize_doc(text_nostop)\n",
    "print(text_lemmatized)\n",
    "\n",
    "tokens_bert = tokenizer(' '.join(text_lemmatized), return_tensors='pt')\n",
    "print(tokens_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1112,  0.6538]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.1462, 0.8538]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"data/review_classifier_tokenizer\")\n",
    "\n",
    "# Load the model\n",
    "model_load = AutoModelForSequenceClassification.from_pretrained(\"data/review_classifier\")\n",
    "\n",
    "# Get the model's predictions\n",
    "predictions = model_load(**tokens_bert)\n",
    "\n",
    "print(predictions.logits)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Apply softmax to output\n",
    "probabilities = F.softmax(predictions.logits, dim=-1)\n",
    "\n",
    "print(probabilities)\n",
    "\n",
    "import torch\n",
    "\n",
    "# Apply softmax to output to get probabilities\n",
    "probabilities = torch.nn.functional.softmax(predictions.logits, dim=-1)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = torch.argmax(probabilities, dim=-1)\n",
    "\n",
    "print(predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8538343906402588"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(max(probabilities[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
